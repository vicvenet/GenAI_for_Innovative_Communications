{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58540140",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vicvenet/GenAI_for_Innovative_Communications/blob/main/2025_S1/Week_8/Social_media_monitoring.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06db4af",
   "metadata": {},
   "source": [
    "# Social Media Emotion Analysis in Chinesewith RoBERTa-WWM\n",
    "This script implements fine-tuning of Chinese RoBERTa-WWM model using LoRA (Low-Rank Adaptation)\n",
    "for the CLUEemotion dataset classification task so that it can be used for emotion\n",
    "analysis of Chinese texts.\n",
    "The reason for using LoRA is that it allows to fine-tune the model with a smaller\n",
    "number of trainable parameters, which is more efficient and easier to manage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7755f76b",
   "metadata": {},
   "source": [
    "Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ae460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch>=2.0.0 transformers>=4.30.0 datasets>=2.12.0 peft>=0.4.0\n",
    "!pip install tqdm>=4.65.0 scikit-learn>=1.2.2 pandas>=2.0.3 seaborn>=0.12.2\n",
    "!pip install matplotlib>=3.5.0 numpy>=1.22.0 requests>=2.28.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141e3129",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4082e6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AdamW,\n",
    "    AutoModelForSeq2SeqLM\n",
    ")\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt  # Still needed as backend for seaborn\n",
    "import numpy as np\n",
    "import requests\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387e96c6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Directory Setup\n",
    "Create necessary directories for saving model, dataset, and tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692549b8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "SAVE_DIR = Path(\"saved_data\")\n",
    "MODEL_DIR = SAVE_DIR / \"model\"\n",
    "DATASET_DIR = SAVE_DIR / \"dataset\"\n",
    "TOKENIZED_DIR = SAVE_DIR / \"tokenized_dataset\"\n",
    "CHARTS_DIR = SAVE_DIR / \"charts\"\n",
    "PROCESSED_INPUTS_DIR = SAVE_DIR / \"processed_inputs\"\n",
    "LORA_DIR = MODEL_DIR / \"trained_LoRA\"  # New directory for LoRA adapters\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(DATASET_DIR, exist_ok=True)\n",
    "os.makedirs(TOKENIZED_DIR, exist_ok=True)\n",
    "os.makedirs(CHARTS_DIR, exist_ok=True)\n",
    "os.makedirs(PROCESSED_INPUTS_DIR, exist_ok=True)\n",
    "os.makedirs(LORA_DIR, exist_ok=True)  # Create LoRA directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ca066b",
   "metadata": {},
   "source": [
    "## GPU Memory Cleanup\n",
    "Clear any existing models from GPU memory to start with a clean state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a76e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clear GPU memory\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"\n",
    "    Clear GPU memory to prevent memory issues when loading models\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"GPU detected. Clearing GPU memory...\")\n",
    "        \n",
    "        # First collect Python garbage to release references\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        \n",
    "        # Empty CUDA cache\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Reset peak memory stats\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        \n",
    "        # Additional memory checks and cleanup\n",
    "        if hasattr(torch.cuda, 'memory_stats'):\n",
    "            before = torch.cuda.memory_allocated() / 1024 / 1024\n",
    "            print(f\"GPU memory in use before cleanup: {before:.2f} MB\")\n",
    "        \n",
    "        # Force synchronize CUDA to complete pending operations\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        # Empty cache again after synchronization\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Report memory after cleanup\n",
    "        if hasattr(torch.cuda, 'memory_stats'):\n",
    "            after = torch.cuda.memory_allocated() / 1024 / 1024\n",
    "            print(f\"GPU memory in use after cleanup: {after:.2f} MB\")\n",
    "        \n",
    "        print(\"GPU memory cleared\")\n",
    "    else:\n",
    "        print(\"No GPU detected, skipping memory cleanup\")\n",
    "\n",
    "# Clear GPU memory at the start\n",
    "clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad7968e",
   "metadata": {},
   "source": [
    "## Dataset Loading\n",
    "Load the CLUEemotion dataset with the Hugging Face dataset library, using cached version if available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea7b5f5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Define the URLs to download the dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f826bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_urls = {\n",
    "    'train': 'https://raw.githubusercontent.com/cque7/CLUEmotionAnalysis2020/master/CLUEdataset/emotion/train.txt',\n",
    "    'valid': 'https://raw.githubusercontent.com/cque7/CLUEmotionAnalysis2020/master/CLUEdataset/emotion/valid.txt',\n",
    "    'test': 'https://raw.githubusercontent.com/cque7/CLUEmotionAnalysis2020/master/CLUEdataset/emotion/test.txt'\n",
    "}\n",
    "\n",
    "# Function to download dataset files\n",
    "def download_dataset_file(url, file_path):\n",
    "    \"\"\"Download a file if it doesn't exist locally\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Downloading {url} to {file_path}...\")\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"Downloaded successfully.\")\n",
    "        else:\n",
    "            raise Exception(f\"Failed to download {url}. Status code: {response.status_code}\")\n",
    "    else:\n",
    "        print(f\"File {file_path} already exists. Skipping download.\")\n",
    "\n",
    "# Create dataset directory for CLUE emotion\n",
    "clue_emotion_dir = DATASET_DIR / \"clue_emotion\"\n",
    "os.makedirs(clue_emotion_dir, exist_ok=True)\n",
    "\n",
    "# Download dataset files\n",
    "local_dataset_files = {}\n",
    "for split, url in dataset_urls.items():\n",
    "    file_path = clue_emotion_dir / f\"{split}.txt\"\n",
    "    local_dataset_files[split] = file_path\n",
    "    download_dataset_file(url, file_path)\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = DATASET_DIR / \"clue_emotion_processed\"\n",
    "if os.path.exists(dataset_path):\n",
    "    print(\"Loading cached dataset...\")\n",
    "    dataset = load_dataset(\"json\", \n",
    "                         data_files={\n",
    "                             'train': str(local_dataset_files['train']),\n",
    "                             'validation': str(local_dataset_files['valid']),\n",
    "                             'test': str(local_dataset_files['test'])\n",
    "                         },\n",
    "                         cache_dir=str(dataset_path))\n",
    "else:\n",
    "    print(\"Loading dataset from files...\")\n",
    "    dataset = load_dataset(\"json\", \n",
    "                         data_files={\n",
    "                             'train': str(local_dataset_files['train']),\n",
    "                             'validation': str(local_dataset_files['valid']),\n",
    "                             'test': str(local_dataset_files['test'])\n",
    "                         })\n",
    "    dataset.save_to_disk(str(dataset_path))\n",
    "\n",
    "# Examine dataset structure\n",
    "print(\"\\nDataset structure:\")\n",
    "for split in dataset:\n",
    "    print(f\"{split}: {dataset[split].features}\")\n",
    "    print(f\"Number of examples: {len(dataset[split])}\")\n",
    "\n",
    "# Check for list-type labels in the dataset\n",
    "def check_label_types(dataset_split):\n",
    "    list_labels_count = 0\n",
    "    string_labels_count = 0\n",
    "    other_labels_count = 0\n",
    "    unique_labels = set()\n",
    "    \n",
    "    for example in dataset_split:\n",
    "        label = example['label']\n",
    "        if isinstance(label, list):\n",
    "            list_labels_count += 1\n",
    "        elif isinstance(label, str):\n",
    "            string_labels_count += 1\n",
    "            unique_labels.add(label)\n",
    "        else:\n",
    "            other_labels_count += 1\n",
    "    \n",
    "    return {\n",
    "        'list_labels': list_labels_count,\n",
    "        'string_labels': string_labels_count,\n",
    "        'other_labels': other_labels_count,\n",
    "        'unique_labels': unique_labels\n",
    "    }\n",
    "\n",
    "print(\"\\nLabel type analysis:\")\n",
    "for split in dataset:\n",
    "    print(f\"\\n{split.upper()} split:\")\n",
    "    label_stats = check_label_types(dataset[split])\n",
    "    print(f\"List labels count: {label_stats['list_labels']}\")\n",
    "    print(f\"String labels count: {label_stats['string_labels']}\")\n",
    "    print(f\"Other labels count: {label_stats['other_labels']}\")\n",
    "    print(f\"Unique string labels: {sorted(label_stats['unique_labels'])}\")\n",
    "\n",
    "# Define the emotion categories from CLUEmotionAnalysis2020 dataset\n",
    "# Based on the README: like, happiness, sadness, anger, disgust, fear and surprise\n",
    "CATEGORIES = [\n",
    "    \"like\",\n",
    "    \"happiness\", \n",
    "    \"sadness\",\n",
    "    \"anger\",\n",
    "    \"disgust\",\n",
    "    \"fear\",\n",
    "    \"surprise\"\n",
    "]\n",
    "num_labels = len(CATEGORIES)\n",
    "print(f\"Number of emotion labels: {num_labels}\")\n",
    "\n",
    "# Create label to id mapping\n",
    "label_to_id = {label: i for i, label in enumerate(CATEGORIES)}\n",
    "\n",
    "# Print first few examples of the training set to verify\n",
    "print(\"\\nSample data from the emotion dataset:\")\n",
    "for i in range(3):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(f\"Content: {dataset['train'][i]['content']}\")\n",
    "    print(f\"Label: {dataset['train'][i]['label']}\")\n",
    "    print(f\"Label ID: {label_to_id.get(dataset['train'][i]['label'], -1)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed0d34",
   "metadata": {},
   "source": [
    "## Model Initialization\n",
    "Initialize the Chinese RoBERTa model and tokenizer using the Hugging Face library transformers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a076646",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Initialize the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53157a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/chinese-roberta-wwm-ext\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cec255c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Initialize or load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d8a57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU memory before loading model\n",
    "clear_gpu_memory()\n",
    "\n",
    "model_path = LORA_DIR / \"chinese_roberta_lora_clue_emotions\"\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Loading saved LoRA adapter...\")\n",
    "    try:\n",
    "        # Attempt to load with memory-efficient settings\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            str(model_path),\n",
    "            num_labels=num_labels,  # Ensure consistent number of labels\n",
    "            torch_dtype=torch.float16,  # Use half precision\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error loading with optimized settings: {e}\")\n",
    "        # Fallback to standard loading\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            str(model_path),\n",
    "            num_labels=num_labels\n",
    "        )\n",
    "else:\n",
    "    print(\"Initializing new model...\")\n",
    "    try:\n",
    "        # Attempt to initialize with memory-efficient settings\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"hfl/chinese-roberta-wwm-ext\",\n",
    "            num_labels=num_labels,\n",
    "            torch_dtype=torch.float16,  # Use half precision\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error initializing with optimized settings: {e}\")\n",
    "        # Fallback to standard initialization\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"hfl/chinese-roberta-wwm-ext\",\n",
    "            num_labels=num_labels\n",
    "        )\n",
    "\n",
    "# Print memory usage after model loading\n",
    "if torch.cuda.is_available() and hasattr(torch.cuda, 'memory_stats'):\n",
    "    mem_allocated = torch.cuda.memory_allocated() / 1024 / 1024\n",
    "    print(f\"GPU memory allocated after model loading: {mem_allocated:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4309c4",
   "metadata": {},
   "source": [
    "## LoRA Configuration\n",
    "Configure Low-Rank Adaptation parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42b289e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Configure LoRa with target modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258a427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    # Target modules for Chinese RoBERTa model\n",
    "    target_modules=[\"query\", \"key\", \"value\", \"output.dense\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f728e3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Apply LoRa to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9467f9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3e46e2",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "Define tokenization function and prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f925fdeb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    # For batched processing\n",
    "    if isinstance(example['content'], list):\n",
    "        # Process each example in the batch\n",
    "        tokenized = tokenizer(\n",
    "            example['content'],  # Using 'content' instead of 'text'\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=145,  # Chinese may need longer sequences due to character-based tokenization\n",
    "            return_tensors=\"pt\"  # Return PyTorch tensors\n",
    "        )\n",
    "        \n",
    "        # Process labels if they exist\n",
    "        if 'label' in example:\n",
    "            labels = []\n",
    "            for label in example['label']:\n",
    "                # Handle case where label might be a list\n",
    "                if isinstance(label, list):\n",
    "                    # If it's a list, take the first element\n",
    "                    if label:\n",
    "                        label = label[0]\n",
    "                    else:\n",
    "                        # Empty list, default to first category\n",
    "                        label = CATEGORIES[0]\n",
    "                \n",
    "                # Now label should be a string, convert to id\n",
    "                labels.append(label_to_id.get(label, 0))  # Default to 0 if not found\n",
    "            \n",
    "            tokenized['labels'] = labels\n",
    "        \n",
    "        return tokenized\n",
    "    \n",
    "    # For single example processing (just in case)\n",
    "    else:\n",
    "        tokenized = tokenizer(\n",
    "            example['content'],  # Using 'content' instead of 'text'\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=512,  # Chinese may need longer sequences due to character-based tokenization\n",
    "            return_tensors=None  # Don't return tensors yet\n",
    "        )\n",
    "        \n",
    "        # Map string emotion labels to numerical indices\n",
    "        if 'label' in example:\n",
    "            label = example['label']\n",
    "            # Handle case where label might be a list\n",
    "            if isinstance(label, list):\n",
    "                # If it's a list, take the first element\n",
    "                if label:\n",
    "                    label = label[0]\n",
    "                else:\n",
    "                    # Empty list, default to first category\n",
    "                    label = CATEGORIES[0]\n",
    "            \n",
    "            # Now label should be a string, convert to id\n",
    "            tokenized['labels'] = label_to_id.get(label, 0)  # Default to 0 if not found\n",
    "        \n",
    "        return tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04264c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Set the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdda863",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d85df4",
   "metadata": {},
   "source": [
    "## Dataset Tokenization\n",
    "Tokenize the dataset and prepare it for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7bda90",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Check if tokenized dataset exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949e8cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_path = TOKENIZED_DIR / \"tokenized_chinese_dataset\"\n",
    "if os.path.exists(tokenized_path):\n",
    "    print(\"Loading cached tokenized dataset...\")\n",
    "    tokenized_dataset = dataset.load_from_disk(str(tokenized_path))\n",
    "else:\n",
    "    print(\"Tokenizing dataset...\")\n",
    "    tokenized_dataset = dataset.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        batch_size=batch_size * 4,  # Process 4 training batches at once for efficiency\n",
    "        remove_columns=dataset[\"train\"].column_names\n",
    "    )\n",
    "    # Set format for PyTorch\n",
    "    tokenized_dataset = tokenized_dataset.with_format(\n",
    "        \"torch\", \n",
    "        columns=[\n",
    "            \"input_ids\", \n",
    "            \"attention_mask\", \n",
    "            \"labels\"\n",
    "        ]\n",
    "    )\n",
    "    tokenized_dataset.save_to_disk(str(tokenized_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb564aab",
   "metadata": {},
   "source": [
    "## Data Loaders\n",
    "Create DataLoaders for training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608ac9f6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Create DataLoader for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7adda1b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    tokenized_dataset[\"train\"],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a7b608",
   "metadata": {},
   "source": [
    "Create DataLoader for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26493efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loader = DataLoader(\n",
    "    tokenized_dataset[\"validation\"],\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a209a2",
   "metadata": {},
   "source": [
    "## Training Setup\n",
    "Configure device and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb80a46f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Some setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873439b6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Clear GPU memory before moving model to device\n",
    "clear_gpu_memory()\n",
    "\n",
    "# Set device to GPU if available, with memory-efficient handling\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model to device with memory-efficient approach\n",
    "if device.type == 'cuda':\n",
    "    try:\n",
    "        # Try to use automatic mixed precision for memory efficiency\n",
    "        print(\"Enabling automatic mixed precision...\")\n",
    "        model = model.to(device)\n",
    "        # Report memory usage after moving model to device\n",
    "        mem_allocated = torch.cuda.memory_allocated() / 1024 / 1024\n",
    "        print(f\"GPU memory allocated after moving model to device: {mem_allocated:.2f} MB\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Error moving model to GPU: {e}\")\n",
    "        print(\"Falling back to CPU...\")\n",
    "        device = torch.device(\"cpu\")\n",
    "        model = model.to(device)\n",
    "else:\n",
    "    model = model.to(device)\n",
    "\n",
    "# Initialize the learning rate, optimizer and number of training epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8151d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-4\n",
    "num_warmup_steps = 500\n",
    "max_grad_norm = 1.0  # For gradient clipping\n",
    "num_epochs = 3\n",
    "\n",
    "model_path = LORA_DIR / \"chinese_roberta_lora_clue_emotions\"\n",
    "\n",
    "# Initialize optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=num_warmup_steps, \n",
    "    num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fc8f87",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "Train the model for the specified number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af1d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print memory status before training\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\nMemory status before training:\")\n",
    "    print(f\"GPU memory allocated: {torch.cuda.memory_allocated() / 1024 / 1024:.2f} MB\")\n",
    "    print(f\"GPU memory reserved: {torch.cuda.memory_reserved() / 1024 / 1024:.2f} MB\")\n",
    "    if hasattr(torch.cuda, 'memory_stats'):\n",
    "        print(f\"GPU memory stats: {torch.cuda.memory_stats()}\")\n",
    "    print(f\"Max memory allocated: {torch.cuda.max_memory_allocated() / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    # Clear memory before each epoch\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Keep track of last 10 batch losses\n",
    "    recent_losses = []\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        # Move batch to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clip gradients\n",
    "        clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Track loss\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Track recent losses (last 10 batches)\n",
    "        recent_losses.append(loss.item())\n",
    "        if len(recent_losses) > 10:\n",
    "            recent_losses.pop(0)\n",
    "        \n",
    "        # Calculate average of recent losses\n",
    "        avg_recent_loss = sum(recent_losses) / len(recent_losses)\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            \"avg_loss_10\": f\"{avg_recent_loss:.4f}\",\n",
    "            \"lr\": f\"{scheduler.get_last_lr()[0]:.2e}\"\n",
    "        })\n",
    "    \n",
    "    # Print epoch summary\n",
    "    avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "    print(f\"\\nEpoch {epoch+1} - Recent Loss (last 10 batches): {avg_recent_loss:.4f}\")\n",
    "    print(f\"Full Epoch Average Loss: {avg_epoch_loss:.4f} (less relevant for training progress)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7684a243",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "Evaluate the model on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b57a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in eval_loader:\n",
    "        # Move batch to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Get predictions\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(batch['labels'].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e646d80d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Calculate accuracy and detailed metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e23d2e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate and print detailed metrics\n",
    "print(\"\\nDetailed Metrics:\")\n",
    "report = classification_report(\n",
    "    all_labels, \n",
    "    all_predictions, \n",
    "    target_names=CATEGORIES,\n",
    "    digits=3\n",
    ")\n",
    "print(report)\n",
    "\n",
    "# Plot confusion matrix\n",
    "confusion = confusion_matrix(all_labels, all_predictions)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    confusion, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=CATEGORIES,\n",
    "    yticklabels=CATEGORIES\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix for Emotion Classification')\n",
    "plt.tight_layout()\n",
    "plt.savefig(CHARTS_DIR / \"emotion_confusion_matrix.png\")\n",
    "# Remove plt.show() as it might be causing the code to hang in non-interactive environments\n",
    "# plt.show()  # Commented out to prevent hanging\n",
    "plt.close()  # Explicitly close the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3459df4",
   "metadata": {},
   "source": [
    "## Test with Examples\n",
    "Try the model on sample Chinese sentences to verify it works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880c789a",
   "metadata": {},
   "source": [
    "def predict_emotion(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Move inputs to device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        prediction = torch.argmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    # Map numerical prediction to emotion name\n",
    "    emotion = CATEGORIES[prediction.item()]\n",
    "    return emotion\n",
    "\n",
    "# Test with examples of each emotion\n",
    "print(\"\\nTesting model with examples for different emotions:\")\n",
    "\n",
    "test_examples = {\n",
    "    \"happiness\": \"今天我非常开心，因为我收到了一个惊喜礼物！\",  # \"I'm very happy today because I received a surprise gift!\"\n",
    "    \"sadness\": \"听到这个消息，我感到非常难过和失落。\",  # \"Hearing this news, I feel very sad and lost.\"\n",
    "    \"anger\": \"我对这种不公平的待遇感到愤怒！\",  # \"I am angry about this unfair treatment!\"\n",
    "    \"fear\": \"我害怕黑暗，总是觉得有什么东西在暗处等着我。\",  # \"I'm afraid of the dark, always feeling like something is waiting for me in the shadows.\"\n",
    "    \"disgust\": \"看到这样肮脏的环境让我感到恶心。\",  # \"Seeing such a dirty environment makes me feel disgusted.\"\n",
    "    \"surprise\": \"突然的爆炸声让我大吃一惊！\",  # \"The sudden noise startled me!\"\n",
    "    \"like\": \"我很喜欢这本书，内容非常吸引人。\"  # \"I really like this book, the content is very interesting.\"\n",
    "}\n",
    "\n",
    "for emotion, text in test_examples.items():\n",
    "    prediction = predict_emotion(text)\n",
    "    print(f\"\\nExample ({emotion}):\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted emotion: {prediction}\")\n",
    "    print(f\"Correct: {'✓' if prediction == emotion else '✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc99e516",
   "metadata": {},
   "source": [
    "## Save Model\n",
    "Save the trained LoRA adapter and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcc847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the LoRA adapter and tokenizer\n",
    "print(\"Saving LoRA adapter and tokenizer...\")\n",
    "model.save_pretrained(str(LORA_DIR / \"chinese_roberta_lora_clue_emotions\"))\n",
    "tokenizer.save_pretrained(str(LORA_DIR / \"chinese_roberta_lora_clue_emotions\"))\n",
    "print(\"Training complete! LoRA adapter and tokenizer saved for Chinese emotion classification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5913581b",
   "metadata": {},
   "source": [
    "## Analyze Weibo Comments on Cathay Pacific\n",
    "Read Weibo comments about Cathay Pacific from GitHub and predict emotions.\n",
    "We retrieve the data directly from a remote source rather than relying on local files,\n",
    "making this notebook more portable and reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d5191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a blue-themed style for seaborn for consistent visualization\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "blue_palette = sns.color_palette(\"Blues_d\", 7)\n",
    "sns.set_palette(blue_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7d6a38",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define the URL to the data file on GitHub\n",
    "github_url = \"https://raw.githubusercontent.com/vicvenet/GenAI_for_Innovative_Communications/main/2025_S1/Week_8/cathay_weibo.txt\"\n",
    "\n",
    "# Read the file directly from GitHub using requests for better portability\n",
    "print(f\"Retrieving Weibo comments from GitHub...\")\n",
    "comments = []\n",
    "try:\n",
    "    # Using requests to fetch the data from GitHub\n",
    "    response = requests.get(github_url)\n",
    "    response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "    \n",
    "    # Process the text data line by line\n",
    "    for line in response.text.splitlines():\n",
    "        if line.strip():  # Skip empty lines\n",
    "            comments.append(line.strip())\n",
    "    \n",
    "    if not comments:\n",
    "        print(f\"Warning: No comments found in the file\")\n",
    "        # Generate some sample data for demonstration purposes\n",
    "        comments = [\n",
    "            \"国泰航空的服务真的很好，空姐非常友善。\",\n",
    "            \"这次航班延误了2小时，真是太糟糕了！\",\n",
    "            \"登机手续办理很快，但行李托运等了很久。\",\n",
    "            \"机餐难吃，而且选择太少了。\",\n",
    "            \"飞机上的娱乐系统不错，电影很新。\"\n",
    "        ]\n",
    "        print(\"Using sample data for demonstration instead.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving data: {str(e)}\")\n",
    "    # Generate some sample data for demonstration purposes\n",
    "    comments = [\n",
    "        \"国泰航空的服务真的很好，空姐非常友善。\",\n",
    "        \"这次航班延误了2小时，真是太糟糕了！\",\n",
    "        \"登机手续办理很快，但行李托运等了很久。\",\n",
    "        \"机餐难吃，而且选择太少了。\",\n",
    "        \"飞机上的娱乐系统不错，电影很新。\"\n",
    "    ]\n",
    "    print(\"Using sample data instead.\")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(comments, columns=[\"text\"])\n",
    "\n",
    "# Display the first few rows to understand the data\n",
    "print(\"\\nFirst 5 comments:\")\n",
    "print(df.head())\n",
    "print(f\"\\nTotal number of comments: {len(df)}\")\n",
    "\n",
    "# Check for maximum text length in characters and tokens\n",
    "char_lengths = df['text'].str.len()\n",
    "print(f\"\\nText length in characters:\")\n",
    "print(f\"Maximum: {char_lengths.max()}\")\n",
    "print(f\"Average: {char_lengths.mean():.1f}\")\n",
    "\n",
    "max_length = 512\n",
    "# Check token lengths using the tokenizer\n",
    "print(\"\\nChecking token lengths with the tokenizer...\")\n",
    "sample_tokens = [len(tokenizer.encode(text)) for text in df['text'].sample(min(100, len(df)))]\n",
    "max_tokens = max(sample_tokens)\n",
    "avg_tokens = sum(sample_tokens) / len(sample_tokens)\n",
    "print(f\"Maximum tokens (from sample): {max_tokens}\")\n",
    "print(f\"Average tokens (from sample): {avg_tokens:.1f}\")\n",
    "print(f\"Current max_length in code: {max_length}\")\n",
    "\n",
    "if max_tokens > max_length:\n",
    "    print(f\"⚠️ Warning: Some texts exceed the current number of tokens the code can handle ({max_length})!\")\n",
    "    print(f\"   Consider increasing max_length to at least {max_tokens}\")\n",
    "else:\n",
    "    print(\"✓ Current max_length setting is sufficient for the texts in this dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d006594",
   "metadata": {},
   "source": [
    "Predict emotions for each comment in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e8a4c2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define a function to predict emotions for a batch of texts to improve efficiency\n",
    "def predict_emotions_batch(texts, batch_size=16):\n",
    "    \"\"\"\n",
    "    Predict emotions for a batch of texts using the fine-tuned RoBERTa model.\n",
    "    \n",
    "    Args:\n",
    "        texts: List or Series of text strings to analyze\n",
    "        batch_size: Number of texts to process at once (default: 16)\n",
    "        \n",
    "    Returns:\n",
    "        List of predicted emotion categories\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    confidence_scores = []\n",
    "    \n",
    "    # Make sure model is in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Process in batches to avoid memory issues\n",
    "    num_batches = (len(texts) + batch_size - 1) // batch_size\n",
    "    print(f\"Processing {len(texts)} comments in {num_batches} batches...\")\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        \n",
    "        try:\n",
    "            # Tokenize all texts in the batch\n",
    "            inputs = tokenizer(\n",
    "                batch_texts.tolist(),\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            # Move inputs to device\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            \n",
    "            # Get predictions\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                # Apply softmax to get probabilities\n",
    "                probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "                predictions = torch.argmax(probs, dim=-1)\n",
    "                \n",
    "                # Get confidence scores for each prediction\n",
    "                batch_confidences = [float(probs[j][predictions[j]].item()) for j in range(len(predictions))]\n",
    "                confidence_scores.extend(batch_confidences)\n",
    "            \n",
    "            # Map numerical predictions to emotion names\n",
    "            batch_emotions = [CATEGORIES[pred.item()] for pred in predictions]\n",
    "            results.extend(batch_emotions)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing batch {i//batch_size + 1}: {str(e)}\")\n",
    "            # Mark as processing error\n",
    "            batch_results = [\"processing_error\"] * len(batch_texts)\n",
    "            batch_confidences = [0.0] * len(batch_texts)\n",
    "            results.extend(batch_results)\n",
    "            confidence_scores.extend(batch_confidences)\n",
    "    \n",
    "    # Analyze the emotion distribution for quality assurance\n",
    "    emotion_distribution = Counter(results)\n",
    "    print(\"\\nEmotion distribution in predictions:\")\n",
    "    for emotion, count in emotion_distribution.most_common():\n",
    "        percentage = count/len(results)*100\n",
    "        print(f\"{emotion}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Quality check - warn if predictions are too homogeneous\n",
    "    most_common = emotion_distribution.most_common(1)[0]\n",
    "    if most_common[1] / len(results) > 0.9 and len(results) > 10 and most_common[0] != \"processing_error\":\n",
    "        print(\"\\nNote: Over 90% of predictions are the same emotion.\")\n",
    "        print(\"This could indicate either a very homogeneous dataset or a potential model bias.\")\n",
    "    \n",
    "    return results, confidence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8377ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict emotions for all comments\n",
    "print(\"Analyzing emotions in Weibo comments...\")\n",
    "predictions, confidences = predict_emotions_batch(df['text'])\n",
    "df['category'] = predictions\n",
    "df['confidence'] = confidences\n",
    "\n",
    "# Display the dataframe with predictions\n",
    "print(\"\\nSample of comments with predicted emotions:\")\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ef181f",
   "metadata": {},
   "source": [
    "## Analyze the Emotion Distribution\n",
    "Create visualizations of the emotional landscape in the comments.\n",
    "Visualization is a crucial part of data analysis as it helps us identify patterns\n",
    "and communicate findings effectively. Here, we create two plots:\n",
    "1. A bar chart showing the absolute count of each emotion\n",
    "2. A pie chart showing the proportional distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e8dbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the emotions\n",
    "emotion_counts = Counter(df['category'])\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "emotion_df = pd.DataFrame({\n",
    "    'Emotion': emotion_counts.keys(),\n",
    "    'Count': emotion_counts.values()\n",
    "}).sort_values('Count', ascending=False)\n",
    "\n",
    "# Plot the emotion distribution using seaborn for a modern, appealing visualization\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Fix deprecated palette parameter by using hue properly\n",
    "emotion_df['Emotion_Hue'] = emotion_df['Emotion']  # Create hue column with same data as x\n",
    "ax = sns.barplot(\n",
    "    x='Emotion', \n",
    "    y='Count',\n",
    "    hue='Emotion_Hue',\n",
    "    data=emotion_df,\n",
    "    palette=\"Blues_d\",\n",
    "    legend=False  # No need for a legend since colors already distinguish bars\n",
    ")\n",
    "\n",
    "sns.despine()  # Remove top and right spines for cleaner look\n",
    "ax.set_title('Emotion Distribution in Cathay Pacific Weibo Comments', fontsize=16)\n",
    "ax.set_xlabel('Emotion', fontsize=14)\n",
    "ax.set_ylabel('Number of Comments', fontsize=14)\n",
    "\n",
    "# Fix the UserWarning by getting ticks first and then setting labels\n",
    "ticks = ax.get_xticks()\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')  # Rotate labels for better readability\n",
    "\n",
    "# Add value labels on top of each bar for precise information\n",
    "for i, p in enumerate(ax.patches):\n",
    "    ax.annotate(\n",
    "        f'{int(p.get_height())}', \n",
    "        (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "        ha='center', \n",
    "        va='bottom', \n",
    "        fontsize=12,\n",
    "        color='darkblue',\n",
    "        xytext=(0, 5),\n",
    "        textcoords='offset points'\n",
    "    )\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
    "plt.savefig(CHARTS_DIR / \"emotion_bar_chart.png\")  # Save the figure\n",
    "\n",
    "# In a notebook this displays the chart without blocking\n",
    "# In a script, we need to be more careful to avoid hanging\n",
    "if 'ipykernel' in sys.modules:\n",
    "    # We're in a notebook environment\n",
    "    plt.show()\n",
    "else:\n",
    "    # We're in a script - don't block\n",
    "    plt.draw()\n",
    "    plt.pause(0.001)  # Small pause to render\n",
    "    plt.close()\n",
    "\n",
    "# Create a pie chart for percentage distribution\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.pie(\n",
    "    emotion_counts.values(), \n",
    "    labels=emotion_counts.keys(),\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=90,\n",
    "    colors=sns.color_palette(\"Blues\", len(emotion_counts))\n",
    ")\n",
    "plt.title('Proportion of Emotions in Cathay Pacific Weibo Comments', fontsize=16)\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.tight_layout()\n",
    "plt.savefig(CHARTS_DIR / \"emotion_pie_chart.png\")  # Save the figure\n",
    "\n",
    "# Handle notebook vs script difference for displaying plots\n",
    "if 'ipykernel' in sys.modules:\n",
    "    # We're in a notebook environment\n",
    "    plt.show()\n",
    "else:\n",
    "    # We're in a script - don't block\n",
    "    plt.draw()\n",
    "    plt.pause(0.001)  # Small pause to render\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60f7d57",
   "metadata": {},
   "source": [
    "## Emotion Distribution Summary\n",
    "Below is a summary of the emotion distribution in the dataset.\n",
    "This provides a quick overview of how customers feel about Cathay Pacific\n",
    "based on their Weibo comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466801ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics in a clear, tabular format\n",
    "print(\"\\nEmotion Distribution Summary:\")\n",
    "for emotion, count in emotion_counts.most_common():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"{emotion}: {count} comments ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d00b6a",
   "metadata": {},
   "source": [
    "## Save Results for Further Analysis\n",
    "We save both the raw results (with emotion labels) and a processed version\n",
    "that includes confidence scores and formatting for easy review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9058e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the analysis results\n",
    "try:\n",
    "    # Save to CSV for data analysis\n",
    "    output_path = Path(\"Social_media_analysis/cathay_weibo_emotion_analysis.csv\")\n",
    "    os.makedirs(output_path.parent, exist_ok=True)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Analysis results saved to {output_path}\")\n",
    "    \n",
    "    # Save processed version with emotions and confidence scores\n",
    "    processed_path = PROCESSED_INPUTS_DIR / \"cathay_weibo_processed.txt\"\n",
    "    with open(processed_path, 'w', encoding='utf-8') as f:\n",
    "        for i, row in df.iterrows():\n",
    "            f.write(f\"Comment {i+1} [Emotion: {row['category']} (Confidence: {row['confidence']:.3f})]: {row['text']}\\n\")\n",
    "    print(f\"Processed comments with emotions saved to {processed_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving analysis results: {str(e)}\")\n",
    "    try:\n",
    "        # Try an alternative location if the primary save fails\n",
    "        alt_path = SAVE_DIR / \"cathay_weibo_emotion_analysis.csv\"\n",
    "        df.to_csv(alt_path, index=False)\n",
    "        print(f\"Analysis results saved to alternative location: {alt_path}\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Could not save analysis results to any location.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9140ca7",
   "metadata": {},
   "source": [
    "## Sample Comments for Each Emotion to Inspect the Model's Performance\n",
    "To better understand the model's predictions, we'll examine sample comments for different emotions.\n",
    "This helps us validate the model's performance and gain insights into how different emotions \n",
    "are expressed in social media comments about Cathay Pacific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870db9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get examples of each emotion for manual inspection\n",
    "print(\"Sampling comments from each emotion category...\")\n",
    "emotion_examples = {}\n",
    "\n",
    "# Get 5 examples of each emotion\n",
    "for emotion in CATEGORIES:\n",
    "    emotion_df = df[df['category'] == emotion].head(5)\n",
    "    if not emotion_df.empty:\n",
    "        emotion_examples[emotion] = emotion_df['text'].tolist()\n",
    "    else:\n",
    "        print(f\"No examples found for emotion: {emotion}\")\n",
    "\n",
    "# Display examples for key emotion categories\n",
    "print(\"\\nExamples from different emotion categories:\")\n",
    "\n",
    "# Group emotions into positive and negative categories\n",
    "negative_emotions = [\"sadness\", \"anger\", \"disgust\", \"fear\"]\n",
    "positive_emotions = [\"happiness\", \"like\", \"surprise\"]\n",
    "\n",
    "for emotion_type, emotions in [(\"Positive\", positive_emotions), (\"Negative\", negative_emotions)]:\n",
    "    print(f\"\\n{emotion_type} Emotion Examples:\")\n",
    "    for emotion in emotions:\n",
    "        if emotion in emotion_examples and emotion_examples[emotion]:\n",
    "            print(f\"\\n{emotion.upper()}:\")\n",
    "            examples = emotion_examples[emotion]\n",
    "            for i, example in enumerate(examples[:2], 1):  # Show just 2 examples for brevity\n",
    "                print(f\"{i}. {example}\")\n",
    "        else:\n",
    "            print(f\"No examples found for {emotion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35356b0c",
   "metadata": {},
   "source": [
    "## Model Performance Insights\n",
    "\n",
    "Obviously, the dataset to analyse only contained negative emotions. But the model wrongly predicted some positive emotions. This is usual for sentiment analysis models.    \n",
    "\n",
    "Understanding model limitations is crucial for responsible data analysis.\n",
    "Here are some key insights about the emotion classification model:\n",
    "\n",
    "- The model may misclassify some comments, especially in cases of subtle sarcasm or complex emotions\n",
    "- Classification accuracy is affected by the quality and diversity of the training data\n",
    "- Chinese text analysis presents unique challenges due to language nuances and cultural context\n",
    "- For production applications, continuous monitoring and model tuning would be necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31988b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up resources\n",
    "print(\"\\nAnalysis complete! Clearing resources...\")\n",
    "\n",
    "# Unload the model from memory to free up resources\n",
    "if 'model' in locals():\n",
    "    del model\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
